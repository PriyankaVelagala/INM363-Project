{"cells":[{"cell_type":"markdown","metadata":{"id":"szQR29sp3EnS"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRd7eIwy3lMz"},"outputs":[],"source":["system_path = '/content/drive/MyDrive/GitHub/INM363-Project'\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append(system_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wOwu4mg3EKs"},"outputs":[],"source":["%%bash\n","# Install deps from \n","# https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md#-linux\n","\n","apt-get update  &> /dev/null\n","\n","\n","apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n","nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n","libopenal-dev timidity libwildmidi-dev unzip  &> /dev/null\n","\n","# Boost libraries\n","apt-get install libboost-all-dev  &> /dev/null"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxLURmm320dA"},"outputs":[],"source":["!pip install vizdoom --quiet\n","!pip install ray --quiet\n","!pip install ray['rllib'] --quiet\n","!pip install Ipython --upgrade --quiet\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VS1T6M3r3pWZ"},"outputs":[],"source":["from src.vizdoom_gym.envs.VizDoomEnv import VizdoomEnv\n","from src.vizdoom_gym.envs.VizDoomEnv_def import VizDoomVeryDenseReward"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QBkzwii3rK3"},"outputs":[],"source":["from ray.tune.registry import register_env\n","import gym\n","import os\n","import ray\n","import ray.rllib.agents.ppo as ppo\n","from ray.rllib.algorithms.callbacks import RE3UpdateCallbacks\n","import shutil\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wHlypTqP3uYp"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device: \", device, \"\\n\")\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"ISS2wOf93yzg"},"source":["# Initialize Ray"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnHEhpIO32qK"},"outputs":[],"source":["#need this to load vizdoom module \n","system_path = '/content/drive/MyDrive/GitHub/INM363-Project/src' \n","sys.path.append(system_path)\n","\n","#need this to use gpu on ray \n","os.environ['PYTHONPATH'] = '/content/drive/MyDrive/GitHub/INM363-Project' \n","os.environ['PYTHONPATH']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-JEpAoj38Bi"},"outputs":[],"source":["\n","chkpt_root = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern\"\n","shutil.rmtree(chkpt_root, ignore_errors=True, onerror=None)\n","\n","\n","ray.shutdown()\n","print(\"Shutdown ray\")\n","\n","# start Ray -- add `local_mode=True` here for debugging\n","ray.init(ignore_reinit_error=True,  num_cpus =2, num_gpus = 1) #local_mode=True,\n","\n","#ray.init(num_cpus= 2, num_gpus=1)\n","\n","print(\"Initialized ray\")\n","\n","# register the custom environment\n","select_env = \"VizDoomVeryDenseReward-v0\"\n","\n","register_env(select_env, lambda config: VizDoomVeryDenseReward())\n","#register_env(select_env, lambda config: VizdoomEnv())\n","\n","print(\"registered environment\")\n"]},{"cell_type":"markdown","metadata":{"id":"zV8H12_g4KJZ"},"source":["# Training config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aF2dBoKZ3-cv"},"outputs":[],"source":["# configure the environment and create agent\n","config = ppo.DEFAULT_CONFIG.copy()\n","config[\"log_level\"] = \"WARN\"\n","config[\"model\"] = {\"dim\": 42, \n","                   \"grayscale\": True,\n","                   }\n","config[\"num_gpus\"] = 1\n","config[\"preprocessor_pref\"] = \"rllib\"\n","config['explore'] = True \n","#config['batch_mode'] = 'complete_episodes'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MkTMoSAdZMDC"},"outputs":[],"source":["\n","class RE3Callbacks(RE3UpdateCallbacks, config[\"callbacks\"]):\n","  pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsf9x6OO6CTI"},"outputs":[],"source":["config[\"framework\"] = \"tf\"\n","\n","#https://github.com/ray-project/ray/blob/c9c3f0745a9291a4de0872bdfa69e4ffdfac3657/rllib/utils/exploration/tests/test_random_encoder.py#L35\n","\n","config[\"seed\"] = 12345\n","config[\"callbacks\"] = RE3Callbacks\n","config[\"exploration_config\"] = {\n","    \"type\": \"RE3\",\n","     # the dimensionality of the observation embedding vectors in latent space.\n","     \"embeds_dim\": 128,\n","     \"rho\": 0.1, # Beta decay factor, used for on-policy algorithm.\n","     \"k_nn\": 7, # Number of neighbours to set for K-NN entropy estimation.\n","     \"encoder_net_config\": {\n","         \"fcnet_hiddens\": [],\n","         \"fcnet_activation\": \"relu\",\n","     },\n","     # `reward = r + beta * intrinsic_reward`\n","     \"beta\": 0.2,\n","     # Schedule to use for beta decay, one of constant\" or \"linear_decay\".\n","     \"beta_schedule\": 'constant',\n","     # Specify, which exploration sub-type to use (usually, the algo's \"default\"\n","     # exploration, e.g. EpsilonGreedy for DQN, StochasticSampling for PG/SAC).\n","     \"sub_exploration\": {\n","         \"type\": \"StochasticSampling\",\n","     }\n","}\n","\n","agent = ppo.PPOTrainer(config, env=select_env)\n","\n","print(\"created agent\")"]},{"cell_type":"markdown","metadata":{"id":"gS6SB-rY7KQm"},"source":["**Training** loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LwJ1itLI75HB"},"outputs":[],"source":["import pandas as pd\n","import time \n","\n","cols = [\"checkpoint\", \"eps_reward_min\", \"eps_reward_mean\", \"eps_reward_max\", \"eps_len_mean\", \"episodes_this_iter\"]\n","results_df = pd.DataFrame(columns = cols) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFoAOc1b773i"},"outputs":[],"source":["chkpt_root = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/no_reward\"\n","chkpt_file  = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/no_reward/checkpoint_000800\"\n","agent.restore(chkpt_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQj5TeNQ8BYN"},"outputs":[],"source":["status = \"{:2d} reward {:6.2f}/{:6.2f}/{:6.2f} len {:4.2f}\"\n","start_n = 0\n","n_iter = 300\n","\n","print(\"started training loop\")\n","time_start = time.time() \n","\n","chkpt_root = chkpt_root = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern\"\n","\n","\n","# train a policy with RLlib using PPO\n","for n in range(start_n, n_iter):\n","  \n","    result = agent.train()\n","\n","    #change this to  10 or 20 \n","    if (n+1) % 20 == 0 or n == 0: \n","      chkpt_file = agent.save(chkpt_root)\n","      print(f\"Saved checkpoint {n+1} at {chkpt_file}\")\n","    #chkpt_file = \"not saving checkpoints\"\n","\n","    print(status.format(\n","        n + 1,\n","        result[\"episode_reward_min\"],\n","        result[\"episode_reward_mean\"],\n","        result[\"episode_reward_max\"],\n","        result[\"episode_len_mean\"]\n","    ))\n","\n","    #save metrics\n","    row = {'checkpoint': n+1,\n","       \"eps_reward_min\": result[\"episode_reward_min\"],\n","       \"eps_reward_mean\": result[\"episode_reward_mean\"],\n","       \"eps_reward_max\": result[\"episode_reward_max\"],\n","       \"eps_len_mean\": result[\"episode_len_mean\"],\n","       \"episodes_this_iter\": result[\"episodes_this_iter\"]\n","       }\n","    results_df = results_df.append(row, ignore_index = True)\n","\n","\n","print(f\"Total time elapsed: {(time.time()-time_start)/60}\")\n","\n","print(\"ending training loop\")\n","\n","ray.shutdown()\n","print(\"shutdown ray\")"]},{"cell_type":"markdown","metadata":{"id":"BEUeBvqg8KdW"},"source":["# save results file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34y4KOYl8MOF"},"outputs":[],"source":["from pathlib import Path \n","\n","fname = chkpt_root + '/result.csv'\n","fpath = Path(fname)\n","fpath.parent.mkdir(parents=True, exist_ok = True)\n","results_df.to_csv(fpath)\n","print(f\"Saved results file to {fname}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOyAhPu37Qnmak3EwtDm7Jy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}