{"cells":[{"cell_type":"markdown","metadata":{"id":"szQR29sp3EnS"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28316,"status":"ok","timestamp":1664298709546,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"qRd7eIwy3lMz","outputId":"451bcdc7-e768-4896-9fb3-14f2574d84f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["system_path = '/content/drive/MyDrive/GitHub/INM363-Project'\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append(system_path)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":36889,"status":"ok","timestamp":1664298748982,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"1wOwu4mg3EKs"},"outputs":[],"source":["%%bash\n","# Install deps from \n","# https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md#-linux\n","\n","apt-get update  &> /dev/null\n","\n","\n","apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n","nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n","libopenal-dev timidity libwildmidi-dev unzip  &> /dev/null\n","\n","# Boost libraries\n","apt-get install libboost-all-dev  &> /dev/null"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325150,"status":"ok","timestamp":1664299074101,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"FxLURmm320dA","outputId":"627a31a7-f937-427d-b659-c0eb89d1c2bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 15.7 MB 16.1 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for vizdoom (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 59.4 MB 1.2 MB/s \n","\u001b[K     |████████████████████████████████| 8.8 MB 39.8 MB/s \n","\u001b[K     |████████████████████████████████| 4.1 MB 56.5 MB/s \n","\u001b[K     |████████████████████████████████| 468 kB 66.4 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 14.2 MB/s \n","\u001b[K     |████████████████████████████████| 626 kB 65.4 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 125 kB 66.7 MB/s \n","\u001b[?25h  Building wheel for gym (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 793 kB 12.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 57.6 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install vizdoom --quiet\n","!pip install ray --quiet\n","!pip install ray['rllib'] --quiet\n","!pip install Ipython --upgrade --quiet\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4096,"status":"ok","timestamp":1664299078181,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"VS1T6M3r3pWZ"},"outputs":[],"source":["from src.vizdoom_gym.envs.VizDoomEnv import VizdoomEnv\n","from src.vizdoom_gym.envs.VizDoomEnv_def import VizDoomVeryDenseReward"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8444,"status":"ok","timestamp":1664299086612,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"9QBkzwii3rK3"},"outputs":[],"source":["from ray.tune.registry import register_env\n","import gym\n","import os\n","import ray\n","import ray.rllib.agents.ppo as ppo\n","from ray.rllib.algorithms.callbacks import RE3UpdateCallbacks\n","import shutil\n","import torch"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84,"status":"ok","timestamp":1664299086613,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"wHlypTqP3uYp","outputId":"40c19278-5b84-4b50-82df-3c994791082b"},"outputs":[{"output_type":"stream","name":"stdout","text":["device:  cuda:0 \n","\n","Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device: \", device, \"\\n\")\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"ISS2wOf93yzg"},"source":["# Initialize Ray"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":79,"status":"ok","timestamp":1664299086615,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"cnHEhpIO32qK","outputId":"4365df3f-084f-4295-8dad-62fe9301e506"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/GitHub/INM363-Project'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}],"source":["#need this to load vizdoom module \n","system_path = '/content/drive/MyDrive/GitHub/INM363-Project/src' \n","sys.path.append(system_path)\n","\n","#need this to use gpu on ray \n","os.environ['PYTHONPATH'] = '/content/drive/MyDrive/GitHub/INM363-Project' \n","os.environ['PYTHONPATH']"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6617,"status":"ok","timestamp":1664299155961,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"X-JEpAoj38Bi","outputId":"391528a5-ec39-4e26-eeb6-052285245875"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shutdown ray\n"]},{"output_type":"stream","name":"stderr","text":["2022-09-27 17:19:12,892\tINFO worker.py:1518 -- Started a local Ray instance.\n"]},{"output_type":"stream","name":"stdout","text":["Initialized ray\n","registered environment\n"]}],"source":["\n","chkpt_root = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern\"\n","shutil.rmtree(chkpt_root, ignore_errors=True, onerror=None)\n","\n","\n","ray.shutdown()\n","print(\"Shutdown ray\")\n","\n","# start Ray -- add `local_mode=True` here for debugging\n","ray.init(ignore_reinit_error=True,  num_cpus =2, num_gpus = 1) #local_mode=True,\n","\n","#ray.init(num_cpus= 2, num_gpus=1)\n","\n","print(\"Initialized ray\")\n","\n","# register the custom environment\n","select_env = \"VizDoomVeryDenseReward-v0\"\n","\n","register_env(select_env, lambda config: VizDoomVeryDenseReward())\n","#register_env(select_env, lambda config: VizdoomEnv())\n","\n","print(\"registered environment\")\n"]},{"cell_type":"markdown","metadata":{"id":"zV8H12_g4KJZ"},"source":["# Training config"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":53,"status":"ok","timestamp":1664299095127,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"aF2dBoKZ3-cv"},"outputs":[],"source":["# configure the environment and create agent\n","config = ppo.DEFAULT_CONFIG.copy()\n","config[\"log_level\"] = \"WARN\"\n","config[\"model\"] = {\"dim\": 42, \n","                   \"grayscale\": True,\n","                   }\n","config[\"num_gpus\"] = 1\n","config[\"preprocessor_pref\"] = \"rllib\"\n","config['explore'] = True \n","#config['batch_mode'] = 'complete_episodes'\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1664299095128,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"MkTMoSAdZMDC"},"outputs":[],"source":["\n","class RE3Callbacks(RE3UpdateCallbacks, config[\"callbacks\"]):\n","  pass\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22686,"status":"ok","timestamp":1664299179848,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"qsf9x6OO6CTI","outputId":"c3879dc0-511b-46fa-d94c-4c0b7def442b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(RolloutWorker pid=9116)\u001b[0m config file: /content/drive/MyDrive/GitHub/INM363-Project/scenarios/custom/very_dense_reward.cfg\n","\u001b[2m\u001b[36m(RolloutWorker pid=9116)\u001b[0m scenario file: /content/drive/MyDrive/GitHub/INM363-Project/scenarios/custom/train/dense_new_pattern_rs.wad\n","\u001b[2m\u001b[36m(RolloutWorker pid=9116)\u001b[0m episode timeout: 400\n","\u001b[2m\u001b[36m(RolloutWorker pid=9116)\u001b[0m screen resolution: 320X240\n","\u001b[2m\u001b[36m(RolloutWorker pid=9115)\u001b[0m config file: /content/drive/MyDrive/GitHub/INM363-Project/scenarios/custom/very_dense_reward.cfg\n","\u001b[2m\u001b[36m(RolloutWorker pid=9115)\u001b[0m scenario file: /content/drive/MyDrive/GitHub/INM363-Project/scenarios/custom/train/dense_new_pattern_rs.wad\n","\u001b[2m\u001b[36m(RolloutWorker pid=9115)\u001b[0m episode timeout: 400\n","\u001b[2m\u001b[36m(RolloutWorker pid=9115)\u001b[0m screen resolution: 320X240\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(RolloutWorker pid=9116)\u001b[0m /usr/local/lib/python3.7/dist-packages/gym/core.py:173: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n","\u001b[2m\u001b[36m(RolloutWorker pid=9116)\u001b[0m   \"Function `env.seed(seed)` is marked as deprecated and will be removed in the future. \"\n","\u001b[2m\u001b[36m(RolloutWorker pid=9115)\u001b[0m 2022-09-27 17:19:24,174\tWARNING env.py:143 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n","\u001b[2m\u001b[36m(RolloutWorker pid=9115)\u001b[0m /usr/local/lib/python3.7/dist-packages/gym/core.py:173: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n","\u001b[2m\u001b[36m(RolloutWorker pid=9115)\u001b[0m   \"Function `env.seed(seed)` is marked as deprecated and will be removed in the future. \"\n","2022-09-27 17:19:38,472\tINFO trainable.py:164 -- Trainable.setup took 22.667 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n","2022-09-27 17:19:38,482\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"]},{"output_type":"stream","name":"stdout","text":["created agent\n"]}],"source":["config[\"framework\"] = \"tf\"\n","\n","#https://github.com/ray-project/ray/blob/c9c3f0745a9291a4de0872bdfa69e4ffdfac3657/rllib/utils/exploration/tests/test_random_encoder.py#L35\n","\n","config[\"seed\"] = 12345\n","config[\"callbacks\"] = RE3Callbacks\n","config[\"exploration_config\"] = {\n","    \"type\": \"RE3\",\n","     # the dimensionality of the observation embedding vectors in latent space.\n","     \"embeds_dim\": 128,\n","     \"rho\": 0.1, # Beta decay factor, used for on-policy algorithm.\n","     \"k_nn\": 7, # Number of neighbours to set for K-NN entropy estimation.\n","     # Configuration for the encoder network, producing embedding vectors from observations.\n","     # This can be used to configure fcnet- or conv_net setups to properly process any\n","     # observation space. By default uses the Policy model configuration.\n","     \"encoder_net_config\": {\n","         \"fcnet_hiddens\": [],\n","         \"fcnet_activation\": \"relu\",\n","     },\n","     # Hyperparameter to choose between exploration and exploitation. A higher value of beta adds\n","     # more importance to the intrinsic reward, as per the following equation\n","     # `reward = r + beta * intrinsic_reward`\n","     \"beta\": 0.2,\n","     # Schedule to use for beta decay, one of constant\" or \"linear_decay\".\n","     \"beta_schedule\": 'constant',\n","     # Specify, which exploration sub-type to use (usually, the algo's \"default\"\n","     # exploration, e.g. EpsilonGreedy for DQN, StochasticSampling for PG/SAC).\n","     \"sub_exploration\": {\n","         \"type\": \"StochasticSampling\",\n","     }\n","}\n","\n","agent = ppo.PPOTrainer(config, env=select_env)\n","\n","print(\"created agent\")"]},{"cell_type":"markdown","metadata":{"id":"gS6SB-rY7KQm"},"source":["**Training** loop"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":298,"status":"ok","timestamp":1664299184049,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"LwJ1itLI75HB"},"outputs":[],"source":["import pandas as pd\n","import time \n","\n","cols = [\"checkpoint\", \"eps_reward_min\", \"eps_reward_mean\", \"eps_reward_max\", \"eps_len_mean\", \"episodes_this_iter\"]\n","results_df = pd.DataFrame(columns = cols) "]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2845,"status":"ok","timestamp":1664299191820,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"qFoAOc1b773i","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae6333eb-9228-4ea4-ed1c-67222f8017fc"},"outputs":[{"output_type":"stream","name":"stderr","text":["2022-09-27 17:19:50,408\tINFO trainable.py:669 -- Restored on 172.28.0.2 from checkpoint: /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/no_reward/checkpoint_000800\n","2022-09-27 17:19:50,414\tINFO trainable.py:677 -- Current state after restoring: {'_iteration': 800, '_timesteps_total': None, '_time_total': 41944.859322309494, '_episodes_total': 9327}\n"]}],"source":["chkpt_root = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/no_reward\"\n","chkpt_file  = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/no_reward/checkpoint_000800\"\n","agent.restore(chkpt_file)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQj5TeNQ8BYN","executionInfo":{"status":"ok","timestamp":1664313464213,"user_tz":-60,"elapsed":14241636,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}},"outputId":"2f46a83d-32fc-4e45-cdad-9be086637edb"},"outputs":[{"output_type":"stream","name":"stdout","text":["started training loop\n","Saved checkpoint 1 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000801\n"," 1 reward   0.00/  2.37/ 13.00 len 89.72\n"," 2 reward   0.00/  2.35/ 13.00 len 91.92\n"," 3 reward   0.00/  2.41/ 13.00 len 89.50\n"," 4 reward   0.00/  2.08/ 13.00 len 90.66\n"," 5 reward   0.00/  1.70/ 12.00 len 91.30\n"," 6 reward   0.00/  1.86/ 13.00 len 91.49\n"," 7 reward   0.00/  2.32/ 13.00 len 89.01\n"," 8 reward   0.00/  2.24/ 12.00 len 89.45\n"," 9 reward   0.00/  2.81/ 12.00 len 84.92\n","10 reward   0.00/  2.80/ 13.00 len 85.20\n","11 reward   0.00/  2.58/ 14.00 len 86.94\n","12 reward   0.00/  2.33/ 14.00 len 89.38\n","13 reward   0.00/  2.18/ 12.00 len 88.71\n","14 reward   0.00/  2.30/ 12.00 len 86.76\n","15 reward   0.00/  2.32/ 13.00 len 89.70\n","16 reward   0.00/  2.62/ 13.00 len 89.46\n","17 reward   0.00/  2.41/ 13.00 len 92.28\n","18 reward   0.00/  2.22/ 13.00 len 92.73\n","19 reward   0.00/  2.41/ 12.00 len 88.87\n","Saved checkpoint 20 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000820\n","20 reward   0.00/  2.46/ 12.00 len 87.86\n","21 reward   0.00/  2.86/ 14.00 len 85.58\n","22 reward   0.00/  3.16/ 14.00 len 83.96\n","23 reward   0.00/  2.91/ 13.00 len 85.84\n","24 reward   0.00/  2.44/ 12.00 len 87.67\n","25 reward   0.00/  2.58/ 13.00 len 89.70\n","26 reward   0.00/  3.13/ 14.00 len 88.12\n","27 reward   0.00/  3.69/ 14.00 len 82.86\n","28 reward   0.00/  3.69/ 14.00 len 80.27\n","29 reward   0.00/  3.24/ 14.00 len 85.60\n","30 reward   0.00/  2.63/ 14.00 len 89.91\n","31 reward   0.00/  2.69/ 14.00 len 87.69\n","32 reward   0.00/  3.22/ 13.00 len 83.38\n","33 reward   0.00/  2.97/ 13.00 len 87.90\n","34 reward   0.00/  2.87/ 13.00 len 89.87\n","35 reward   0.00/  3.28/ 14.00 len 86.45\n","36 reward   0.00/  3.55/ 14.00 len 85.30\n","37 reward   0.00/  3.46/ 14.00 len 84.68\n","38 reward   0.00/  3.48/ 14.00 len 83.04\n","39 reward   0.00/  2.48/ 14.00 len 90.79\n","Saved checkpoint 40 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000840\n","40 reward   0.00/  3.08/ 14.00 len 89.55\n","41 reward   0.00/  2.83/ 14.00 len 89.17\n","42 reward   0.00/  2.64/ 14.00 len 88.14\n","43 reward   0.00/  2.72/ 14.00 len 89.24\n","44 reward   0.00/  2.86/ 13.00 len 90.57\n","45 reward   0.00/  2.76/ 13.00 len 91.22\n","46 reward   0.00/  2.69/ 11.00 len 89.25\n","47 reward   0.00/  3.18/ 15.00 len 86.51\n","48 reward   0.00/  3.83/ 15.00 len 86.33\n","49 reward   0.00/  3.30/ 12.00 len 89.25\n","50 reward   0.00/  2.96/ 14.00 len 91.45\n","51 reward   0.00/  2.74/ 14.00 len 92.45\n","52 reward   0.00/  2.33/ 12.00 len 93.40\n","53 reward   0.00/  2.30/ 12.00 len 91.77\n","54 reward   0.00/  2.39/ 14.00 len 92.31\n","55 reward   0.00/  2.57/ 14.00 len 94.07\n","56 reward   0.00/  2.69/ 13.00 len 90.46\n","57 reward   0.00/  2.97/ 15.00 len 87.38\n","58 reward   0.00/  3.13/ 15.00 len 87.03\n","59 reward   0.00/  2.59/ 13.00 len 92.27\n","Saved checkpoint 60 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000860\n","60 reward   0.00/  2.50/ 12.00 len 93.75\n","61 reward   0.00/  2.25/ 12.00 len 96.00\n","62 reward   0.00/  2.53/ 14.00 len 95.47\n","63 reward   0.00/  3.13/ 14.00 len 90.56\n","64 reward   0.00/  3.46/ 14.00 len 84.77\n","65 reward   0.00/  3.49/ 13.00 len 84.58\n","66 reward   0.00/  3.45/ 13.00 len 87.77\n","67 reward   0.00/  2.81/ 13.00 len 89.44\n","68 reward   0.00/  2.56/ 10.00 len 87.75\n","69 reward   0.00/  2.27/ 11.00 len 91.80\n","70 reward   0.00/  2.20/ 12.00 len 93.14\n","71 reward   0.00/  3.09/ 15.00 len 86.64\n","72 reward   0.00/  3.30/ 15.00 len 85.39\n","73 reward   0.00/  2.88/ 15.00 len 86.49\n","74 reward   0.00/  2.70/ 14.00 len 91.75\n","75 reward   0.00/  3.47/ 14.00 len 90.30\n","76 reward   0.00/  3.76/ 14.00 len 87.42\n","77 reward   0.00/  2.86/ 14.00 len 88.72\n","78 reward   0.00/  2.65/ 13.00 len 89.35\n","79 reward   0.00/  2.70/ 14.00 len 93.34\n","Saved checkpoint 80 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000880\n","80 reward   0.00/  3.59/ 14.00 len 87.90\n","81 reward   0.00/  3.53/ 14.00 len 87.69\n","82 reward   0.00/  3.35/ 14.00 len 92.04\n","83 reward   0.00/  3.75/ 14.00 len 89.90\n","84 reward   0.00/  3.37/ 14.00 len 91.15\n","85 reward   0.00/  3.35/ 13.00 len 88.13\n","86 reward   0.00/  3.34/ 13.00 len 85.17\n","87 reward   0.00/  4.03/ 15.00 len 86.68\n","88 reward   0.00/  3.72/ 15.00 len 89.35\n","89 reward   0.00/  3.95/ 15.00 len 87.50\n","90 reward   0.00/  3.79/ 15.00 len 83.83\n","91 reward   0.00/  3.30/ 15.00 len 88.67\n","92 reward   0.00/  3.39/ 14.00 len 88.70\n","93 reward   0.00/  4.34/ 15.00 len 82.41\n","94 reward   0.00/  4.31/ 15.00 len 83.11\n","95 reward   0.00/  3.26/ 14.00 len 87.25\n","96 reward   0.00/  3.30/ 14.00 len 87.32\n","97 reward   0.00/  3.54/ 14.00 len 86.03\n","98 reward   0.00/  3.70/ 15.00 len 85.75\n","99 reward   0.00/  4.09/ 15.00 len 84.56\n","Saved checkpoint 100 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000900\n","100 reward   0.00/  3.49/ 14.00 len 88.85\n","101 reward   0.00/  3.67/ 15.00 len 85.54\n","102 reward   0.00/  4.02/ 15.00 len 81.62\n","103 reward   0.00/  4.04/ 15.00 len 85.16\n","104 reward   0.00/  3.43/ 15.00 len 90.19\n","105 reward   0.00/  3.12/ 15.00 len 90.78\n","106 reward   0.00/  3.05/ 15.00 len 89.89\n","107 reward   0.00/  2.55/ 15.00 len 91.06\n","108 reward   0.00/  3.78/ 14.00 len 83.23\n","109 reward   0.00/  4.38/ 14.00 len 81.59\n","110 reward   0.00/  3.34/ 14.00 len 89.47\n","111 reward   0.00/  3.20/ 14.00 len 87.82\n","112 reward   0.00/  3.77/ 14.00 len 82.50\n","113 reward   0.00/  3.44/ 14.00 len 86.21\n","114 reward   0.00/  3.25/ 14.00 len 89.53\n","115 reward   0.00/  3.80/ 14.00 len 88.26\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ray/rllib/utils/metrics/learner_info.py:110: RuntimeWarning: Mean of empty slice\n","  return np.nanmean(tower_data)\n"]},{"output_type":"stream","name":"stdout","text":["116 reward   0.00/  4.03/ 15.00 len 83.88\n","117 reward   0.00/  4.44/ 15.00 len 78.61\n","118 reward   0.00/  4.59/ 14.00 len 77.62\n","119 reward   0.00/  4.22/ 14.00 len 79.83\n","Saved checkpoint 120 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000920\n","120 reward   0.00/  4.19/ 13.00 len 82.55\n","121 reward   0.00/  4.35/ 14.00 len 82.14\n","122 reward   0.00/  4.20/ 15.00 len 79.74\n","123 reward   0.00/  4.16/ 15.00 len 78.90\n","124 reward   0.00/  3.95/ 14.00 len 80.20\n","125 reward   0.00/  3.55/ 15.00 len 86.06\n","126 reward   0.00/  3.52/ 15.00 len 86.07\n","127 reward   0.00/  3.97/ 15.00 len 83.13\n","128 reward   0.00/  3.97/ 15.00 len 81.48\n","129 reward   0.00/  3.73/ 15.00 len 83.42\n","130 reward   0.00/  3.57/ 15.00 len 85.11\n","131 reward   0.00/  3.81/ 14.00 len 82.22\n","132 reward   0.00/  4.04/ 14.00 len 83.56\n","133 reward   0.00/  3.46/ 14.00 len 91.36\n","134 reward   0.00/  3.26/ 14.00 len 93.37\n","135 reward   0.00/  3.83/ 14.00 len 84.61\n","136 reward   0.00/  4.63/ 15.00 len 77.94\n","137 reward   0.00/  4.40/ 15.00 len 81.03\n","138 reward   0.00/  4.36/ 15.00 len 81.21\n","139 reward   0.00/  4.48/ 15.00 len 81.32\n","Saved checkpoint 140 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000940\n","140 reward   0.00/  4.30/ 15.00 len 80.23\n","141 reward   0.00/  5.08/ 15.00 len 77.74\n","142 reward   0.00/  5.12/ 15.00 len 79.20\n","143 reward   0.00/  4.37/ 14.00 len 80.52\n","144 reward   0.00/  3.72/ 15.00 len 85.41\n","145 reward   0.00/  4.11/ 15.00 len 80.42\n","146 reward   0.00/  4.77/ 15.00 len 77.25\n","147 reward   0.00/  5.18/ 15.00 len 77.48\n","148 reward   0.00/  5.27/ 15.00 len 78.67\n","149 reward   0.00/  4.88/ 15.00 len 78.46\n","150 reward   0.00/  4.33/ 15.00 len 80.77\n","151 reward   0.00/  4.12/ 15.00 len 84.05\n","152 reward   0.00/  3.88/ 15.00 len 82.67\n","153 reward   0.00/  4.12/ 15.00 len 80.18\n","154 reward   0.00/  5.08/ 15.00 len 77.83\n","155 reward   0.00/  6.23/ 15.00 len 72.16\n","156 reward   0.00/  6.36/ 15.00 len 71.40\n","157 reward   0.00/  5.40/ 15.00 len 73.64\n","158 reward   0.00/  4.67/ 15.00 len 78.47\n","159 reward   0.00/  4.17/ 14.00 len 82.44\n","Saved checkpoint 160 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000960\n","160 reward   0.00/  3.74/ 14.00 len 83.72\n","161 reward   0.00/  3.97/ 15.00 len 79.15\n","162 reward   0.00/  4.31/ 15.00 len 79.87\n","163 reward   0.00/  4.99/ 15.00 len 80.56\n","164 reward   0.00/  5.72/ 15.00 len 75.44\n","165 reward   0.00/  5.34/ 15.00 len 77.35\n","166 reward   0.00/  4.40/ 15.00 len 82.40\n","167 reward   0.00/  3.91/ 14.00 len 82.94\n","168 reward   0.00/  3.77/ 15.00 len 83.96\n","169 reward   0.00/  4.25/ 15.00 len 83.32\n","170 reward   0.00/  5.43/ 15.00 len 79.75\n","171 reward   0.00/  5.75/ 15.00 len 76.19\n","172 reward   0.00/  5.29/ 15.00 len 71.97\n","173 reward   0.00/  5.16/ 15.00 len 76.29\n","174 reward   0.00/  5.20/ 15.00 len 76.62\n","175 reward   0.00/  5.39/ 14.00 len 75.91\n","176 reward   0.00/  5.44/ 14.00 len 75.99\n","177 reward   0.00/  5.03/ 15.00 len 77.97\n","178 reward   0.00/  4.85/ 15.00 len 77.99\n","179 reward   0.00/  5.70/ 14.00 len 72.69\n","Saved checkpoint 180 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_000980\n","180 reward   0.00/  5.88/ 14.00 len 74.58\n","181 reward   0.00/  5.75/ 14.00 len 76.79\n","182 reward   0.00/  5.63/ 15.00 len 76.69\n","183 reward   0.00/  5.06/ 15.00 len 78.07\n","184 reward   0.00/  4.73/ 15.00 len 79.27\n","185 reward   0.00/  4.69/ 14.00 len 81.54\n","186 reward   0.00/  5.27/ 15.00 len 76.50\n","187 reward   0.00/  5.38/ 15.00 len 74.48\n","188 reward   0.00/  5.99/ 15.00 len 69.98\n","189 reward   0.00/  5.67/ 15.00 len 73.36\n","190 reward   0.00/  5.42/ 15.00 len 76.22\n","191 reward   0.00/  5.49/ 15.00 len 74.17\n","192 reward   0.00/  6.02/ 15.00 len 71.75\n","193 reward   0.00/  5.79/ 15.00 len 68.87\n","194 reward   0.00/  5.21/ 15.00 len 71.62\n","195 reward   0.00/  5.50/ 15.00 len 70.06\n","196 reward   0.00/  6.19/ 15.00 len 67.26\n","197 reward   0.00/  4.99/ 14.00 len 74.45\n","198 reward   0.00/  5.48/ 15.00 len 70.73\n","199 reward   0.00/  6.36/ 15.00 len 67.14\n","Saved checkpoint 200 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_001000\n","200 reward   0.00/  5.79/ 15.00 len 72.06\n","201 reward   0.00/  5.67/ 15.00 len 69.50\n","202 reward   0.00/  5.39/ 15.00 len 73.19\n","203 reward   0.00/  4.95/ 15.00 len 75.60\n","204 reward   0.00/  6.31/ 15.00 len 67.18\n","205 reward   0.00/  6.57/ 15.00 len 67.83\n","206 reward   0.00/  6.01/ 15.00 len 69.18\n","207 reward   0.00/  5.86/ 14.00 len 68.16\n","208 reward   0.00/  6.24/ 14.00 len 65.67\n","209 reward   0.00/  5.86/ 15.00 len 69.19\n","210 reward   0.00/  5.73/ 15.00 len 71.82\n","211 reward   0.00/  6.04/ 15.00 len 73.08\n","212 reward   0.00/  6.48/ 15.00 len 63.57\n","213 reward   0.00/  5.36/ 15.00 len 70.64\n","214 reward   0.00/  5.70/ 15.00 len 65.76\n","215 reward   0.00/  6.79/ 15.00 len 63.71\n","216 reward   0.00/  7.24/ 15.00 len 61.82\n","217 reward   0.00/  6.73/ 15.00 len 62.38\n","218 reward   0.00/  6.84/ 15.00 len 59.71\n","219 reward   0.00/  6.94/ 15.00 len 66.97\n","Saved checkpoint 220 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_001020\n","220 reward   0.00/  7.51/ 15.00 len 59.56\n","221 reward   0.00/  5.96/ 15.00 len 67.50\n","222 reward   0.00/  5.69/ 15.00 len 70.06\n","223 reward   0.00/  5.69/ 15.00 len 70.28\n","224 reward   0.00/  5.85/ 15.00 len 67.88\n","225 reward   0.00/  5.92/ 15.00 len 65.11\n","226 reward   0.00/  6.53/ 15.00 len 59.69\n","227 reward   0.00/  6.16/ 15.00 len 67.74\n","228 reward   0.00/  6.82/ 15.00 len 67.38\n","229 reward   0.00/  6.77/ 15.00 len 63.10\n","230 reward   0.00/  7.09/ 15.00 len 60.80\n","231 reward   0.00/  7.12/ 15.00 len 60.49\n","232 reward   0.00/  6.37/ 15.00 len 65.04\n","233 reward   0.00/  6.00/ 15.00 len 68.37\n","234 reward   0.00/  6.87/ 15.00 len 61.19\n","235 reward   0.00/  7.12/ 15.00 len 61.43\n","236 reward   0.00/  7.00/ 15.00 len 64.97\n","237 reward   0.00/  7.41/ 15.00 len 58.22\n","238 reward   0.00/  6.60/ 15.00 len 60.65\n","239 reward   0.00/  6.23/ 15.00 len 63.90\n","Saved checkpoint 240 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_001040\n","240 reward   0.00/  7.43/ 15.00 len 56.69\n","241 reward   0.00/  6.59/ 15.00 len 64.43\n","242 reward   0.00/  6.89/ 15.00 len 63.85\n","243 reward   0.00/  6.32/ 15.00 len 67.26\n","244 reward   0.00/  6.49/ 15.00 len 69.03\n","245 reward   0.00/  6.73/ 15.00 len 67.48\n","246 reward   0.00/  6.23/ 15.00 len 69.15\n","247 reward   0.00/  6.62/ 15.00 len 64.81\n","248 reward   0.00/  7.07/ 15.00 len 63.38\n","249 reward   0.00/  6.97/ 15.00 len 65.58\n","250 reward   0.00/  6.84/ 15.00 len 62.53\n","251 reward   0.00/  6.91/ 15.00 len 63.21\n","252 reward   0.00/  6.69/ 16.00 len 67.67\n","253 reward   0.00/  6.82/ 15.00 len 65.58\n","254 reward   0.00/  7.71/ 15.00 len 58.48\n","255 reward   0.00/  7.35/ 15.00 len 59.80\n","256 reward   0.00/  7.59/ 15.00 len 60.47\n","257 reward   0.00/  7.16/ 15.00 len 63.65\n","258 reward   0.00/  6.83/ 15.00 len 63.37\n","259 reward   0.00/  7.19/ 15.00 len 64.45\n","Saved checkpoint 260 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_001060\n","260 reward   0.00/  7.66/ 15.00 len 60.16\n","261 reward   0.00/  8.02/ 16.00 len 55.75\n","262 reward   0.00/  7.27/ 15.00 len 57.59\n","263 reward   0.00/  6.67/ 14.00 len 64.46\n","264 reward   0.00/  7.82/ 15.00 len 60.96\n","265 reward   0.00/  7.10/ 15.00 len 64.09\n","266 reward   0.00/  6.32/ 15.00 len 67.54\n","267 reward   0.00/  6.86/ 15.00 len 67.23\n","268 reward   0.00/  6.90/ 15.00 len 60.81\n","269 reward   0.00/  6.66/ 15.00 len 62.72\n","270 reward   0.00/  7.10/ 15.00 len 64.21\n","271 reward   0.00/  7.59/ 15.00 len 63.06\n","272 reward   0.00/  8.00/ 15.00 len 62.31\n","273 reward   0.00/  7.91/ 15.00 len 63.92\n","274 reward   0.00/  8.63/ 15.00 len 57.26\n","275 reward   0.00/  8.53/ 15.00 len 61.20\n","276 reward   0.00/  7.89/ 15.00 len 65.43\n","277 reward   0.00/  8.04/ 15.00 len 65.99\n","278 reward   0.00/  7.78/ 15.00 len 63.32\n","279 reward   0.00/  8.09/ 15.00 len 64.35\n","Saved checkpoint 280 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_001080\n","280 reward   0.00/  7.81/ 15.00 len 67.75\n","281 reward   0.00/  7.47/ 15.00 len 71.13\n","282 reward   0.00/ 10.25/ 15.00 len 51.08\n","283 reward   0.00/  9.09/ 15.00 len 60.26\n","284 reward   0.00/  9.19/ 16.00 len 64.72\n","285 reward   0.00/  8.45/ 16.00 len 64.61\n","286 reward   0.00/  8.26/ 16.00 len 67.41\n","287 reward   0.00/  8.32/ 16.00 len 68.07\n","288 reward   0.00/  8.47/ 16.00 len 68.98\n","289 reward   0.00/  8.46/ 16.00 len 69.21\n","290 reward   0.00/  8.54/ 16.00 len 71.95\n","291 reward   0.00/  8.47/ 16.00 len 66.08\n","292 reward   0.00/  8.76/ 16.00 len 65.23\n","293 reward   0.00/  7.95/ 15.00 len 68.59\n","294 reward   0.00/  8.31/ 15.00 len 68.43\n","295 reward   0.00/  8.80/ 16.00 len 65.87\n","296 reward   0.00/  8.74/ 16.00 len 63.82\n","297 reward   0.00/  9.88/ 16.00 len 63.36\n","298 reward   0.00/  9.41/ 15.00 len 63.62\n","299 reward   0.00/  8.71/ 15.00 len 66.87\n","Saved checkpoint 300 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/checkpoint_001100\n","300 reward   0.00/  9.46/ 15.00 len 59.84\n","Total time elapsed: 237.31984278758367\n","ending training loop\n","shutdown ray\n"]}],"source":["status = \"{:2d} reward {:6.2f}/{:6.2f}/{:6.2f} len {:4.2f}\"\n","start_n = 0\n","n_iter = 300\n","\n","print(\"started training loop\")\n","time_start = time.time() \n","\n","chkpt_root = chkpt_root = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern\"\n","\n","\n","# train a policy with RLlib using PPO\n","for n in range(start_n, n_iter):\n","  \n","    result = agent.train()\n","\n","    #change this to  10 or 20 \n","    if (n+1) % 20 == 0 or n == 0: \n","      chkpt_file = agent.save(chkpt_root)\n","      print(f\"Saved checkpoint {n+1} at {chkpt_file}\")\n","    #chkpt_file = \"not saving checkpoints\"\n","\n","    print(status.format(\n","        n + 1,\n","        result[\"episode_reward_min\"],\n","        result[\"episode_reward_mean\"],\n","        result[\"episode_reward_max\"],\n","        result[\"episode_len_mean\"]\n","    ))\n","\n","    #save metrics\n","    row = {'checkpoint': n+1,\n","       \"eps_reward_min\": result[\"episode_reward_min\"],\n","       \"eps_reward_mean\": result[\"episode_reward_mean\"],\n","       \"eps_reward_max\": result[\"episode_reward_max\"],\n","       \"eps_len_mean\": result[\"episode_len_mean\"],\n","       \"episodes_this_iter\": result[\"episodes_this_iter\"]\n","       }\n","    results_df = results_df.append(row, ignore_index = True)\n","\n","\n","print(f\"Total time elapsed: {(time.time()-time_start)/60}\")\n","\n","print(\"ending training loop\")\n","\n","ray.shutdown()\n","print(\"shutdown ray\")"]},{"cell_type":"markdown","metadata":{"id":"BEUeBvqg8KdW"},"source":["# save results file"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34y4KOYl8MOF","executionInfo":{"status":"ok","timestamp":1664313464215,"user_tz":-60,"elapsed":82,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}},"outputId":"66ce70e7-4533-4249-9344-3dc31d396ebc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved results file to /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/re3/dense_new_pattern/result.csv\n"]}],"source":["from pathlib import Path \n","\n","fname = chkpt_root + '/result.csv'\n","fpath = Path(fname)\n","fpath.parent.mkdir(parents=True, exist_ok = True)\n","results_df.to_csv(fpath)\n","print(f\"Saved results file to {fname}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"ukGquKpMjCU1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNj9ym+XUSpZLeWPK46kNqL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}