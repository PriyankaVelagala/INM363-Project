{"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"TI7XOyssbS4P"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fOEONnatDpVm"},"outputs":[],"source":["%%bash\n","# Install deps from \n","# https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md#-linux\n","\n","apt-get update\n","\n","\n","apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n","nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n","libopenal-dev timidity libwildmidi-dev unzip\n","\n","# Boost libraries\n","apt-get install libboost-all-dev"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"RJA41C07GiJI","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1663590500066,"user_tz":-60,"elapsed":301965,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}},"outputId":"d1e90054-d0e6-42e2-8139-54ad891283d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting vizdoom\n","  Downloading vizdoom-1.1.13.tar.gz (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 1.8 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vizdoom) (1.21.6)\n","Building wheels for collected packages: vizdoom\n","  Building wheel for vizdoom (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vizdoom: filename=vizdoom-1.1.13-cp37-cp37m-linux_x86_64.whl size=14101153 sha256=74cba8fbb0e2f22d3b16568391761ab73aa11e2343930e554ae08cc6dbb2a8a6\n","  Stored in directory: /root/.cache/pip/wheels/ac/37/ae/8e648023f66bb4c473701f94ce126032ff39ad9759ca0645a7\n","Successfully built vizdoom\n","Installing collected packages: vizdoom\n","Successfully installed vizdoom-1.1.13\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ray\n","  Downloading ray-2.0.0-cp37-cp37m-manylinux2014_x86_64.whl (59.4 MB)\n","\u001b[K     |████████████████████████████████| 59.4 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (6.0)\n","Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (22.1.0)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray) (1.2.0)\n","Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n","Collecting virtualenv\n","  Downloading virtualenv-20.16.5-py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 50.9 MB/s \n","\u001b[?25hCollecting grpcio<=1.43.0,>=1.28.1\n","  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 46.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.8.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray) (4.1.1)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.9.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.12.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.6.15)\n","Collecting distlib<1,>=0.3.5\n","  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n","\u001b[K     |████████████████████████████████| 468 kB 67.1 MB/s \n","\u001b[?25hCollecting platformdirs<3,>=2.4\n","  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n","Installing collected packages: platformdirs, distlib, virtualenv, grpcio, ray\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.48.1\n","    Uninstalling grpcio-1.48.1:\n","      Successfully uninstalled grpcio-1.48.1\n","Successfully installed distlib-0.3.6 grpcio-1.43.0 platformdirs-2.5.2 ray-2.0.0 virtualenv-20.16.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ray[rllib] in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.43.0)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.3.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (6.0)\n","Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (7.1.2)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.2.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (4.3.3)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.21.6)\n","Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.17.3)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (22.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.8.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (2.23.0)\n","Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (20.16.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (4.1.1)\n","Collecting tensorboardX>=1.9\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.1.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.3.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.18.3)\n","Collecting gym<0.24.0,>=0.21.0\n","  Downloading gym-0.23.1.tar.gz (626 kB)\n","\u001b[K     |████████████████████████████████| 626 kB 11.7 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.8.10)\n","Collecting lz4\n","  Downloading lz4-4.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 66.1 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.7.3)\n","Requirement already satisfied: matplotlib!=3.4.3 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.2.2)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[rllib]) (1.15.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym<0.24.0,>=0.21.0->ray[rllib]) (0.0.8)\n","Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.24.0,>=0.21.0->ray[rllib]) (4.12.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.24.0,>=0.21.0->ray[rllib]) (1.5.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->gym<0.24.0,>=0.21.0->ray[rllib]) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (3.0.9)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[rllib]) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[rllib]) (5.9.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[rllib]) (2022.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (2.10)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2021.11.2)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (7.1.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2.9.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (1.3.0)\n","Requirement already satisfied: distlib<1,>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[rllib]) (0.3.6)\n","Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[rllib]) (2.5.2)\n","Building wheels for collected packages: gym\n","  Building wheel for gym (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.23.1-py3-none-any.whl size=701378 sha256=43ce3338ad9c0713392ca122130401eddd3331060bcf3b48a1940a6b62c0812f\n","  Stored in directory: /root/.cache/pip/wheels/e3/33/04/6723848e46f0f1ebe794bb329b7c761c3329a0d7ffade99da7\n","Successfully built gym\n","Installing collected packages: tensorboardX, lz4, gym\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","Successfully installed gym-0.23.1 lz4-4.0.2 tensorboardX-2.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Ipython in /usr/local/lib/python3.7/dist-packages (7.9.0)\n","Collecting Ipython\n","  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n","\u001b[K     |████████████████████████████████| 793 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from Ipython) (0.2.0)\n","Collecting matplotlib-inline\n","  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from Ipython) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from Ipython) (57.4.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from Ipython) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from Ipython) (2.6.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from Ipython) (2.0.10)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from Ipython) (0.7.5)\n","Collecting jedi>=0.16\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 66.7 MB/s \n","\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from Ipython) (5.1.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->Ipython) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->Ipython) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython) (1.15.0)\n","Installing collected packages: matplotlib-inline, jedi, Ipython\n","  Attempting uninstall: Ipython\n","    Found existing installation: ipython 7.9.0\n","    Uninstalling ipython-7.9.0:\n","      Successfully uninstalled ipython-7.9.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n","Successfully installed Ipython-7.34.0 jedi-0.18.1 matplotlib-inline-0.1.6\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython"]}}},"metadata":{}}],"source":["!pip install vizdoom\n","!pip install ray \n","!pip install ray['rllib']\n","!pip install Ipython --upgrade\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2520,"status":"ok","timestamp":1663590609334,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"kylByuIvFbYC","outputId":"f64b3571-c38f-4e18-ac42-ab274b082072"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["system_path = '/content/drive/MyDrive/GitHub/INM363-Project'\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append(system_path)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"WldQjKYwGDNi","executionInfo":{"status":"ok","timestamp":1663590612149,"user_tz":-60,"elapsed":1375,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}}},"outputs":[],"source":["from src.vizdoom_gym.envs.VizDoomEnv import VizdoomEnv\n","from src.vizdoom_gym.envs.VizDoomEnv_def import VizDoomVeryDenseReward"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6320,"status":"ok","timestamp":1663590619654,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"hppEzlrdDzQi"},"outputs":[],"source":["from ray.tune.registry import register_env\n","import gym\n","import os\n","import ray\n","import ray.rllib.agents.ppo as ppo\n","import shutil\n","import torch"]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device: \", device, \"\\n\")\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xbceb5K0dSmB","executionInfo":{"status":"ok","timestamp":1663590621936,"user_tz":-60,"elapsed":771,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}},"outputId":"d3dd866d-d984-46de-d3a8-bafaa422fc62"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["device:  cuda:0 \n","\n","Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}]},{"cell_type":"markdown","source":["# Initialize Ray"],"metadata":{"id":"O2flC16pdWYs"}},{"cell_type":"code","source":["#need this to load vizdoom module \n","system_path = '/content/drive/MyDrive/GitHub/INM363-Project/src' \n","sys.path.append(system_path)\n","\n","#need this to use gpu on ray \n","os.environ['PYTHONPATH'] = '/content/drive/MyDrive/GitHub/INM363-Project' \n","os.environ['PYTHONPATH']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"n7VzA--ndaDM","executionInfo":{"status":"ok","timestamp":1663590627052,"user_tz":-60,"elapsed":325,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}},"outputId":"ac6724ec-b9a7-4b7c-9cdf-d4121106f646"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/GitHub/INM363-Project'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3877,"status":"ok","timestamp":1663590632485,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"7g8k4mExHMz2","outputId":"bb94aace-96d4-475b-91da-c200b7f83abf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shutdown ray\n"]},{"output_type":"stream","name":"stderr","text":["2022-09-19 12:30:31,130\tINFO worker.py:1518 -- Started a local Ray instance.\n"]},{"output_type":"stream","name":"stdout","text":["Initialized ray\n","registered environment\n"]}],"source":["\n","chkpt_root = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/icm/easy_no_reward\"\n","shutil.rmtree(chkpt_root, ignore_errors=True, onerror=None)\n","\n","\n","ray.shutdown()\n","print(\"Shutdown ray\")\n","\n","# start Ray -- add `local_mode=True` here for debugging\n","ray.init(ignore_reinit_error=True,  num_cpus =2, num_gpus = 1) #local_mode=True,\n","\n","#ray.init(num_cpus= 2, num_gpus=1)\n","\n","print(\"Initialized ray\")\n","\n","# register the custom environment\n","select_env = \"VizDoomVeryDenseReward-v0\"\n","\n","register_env(select_env, lambda config: VizDoomVeryDenseReward())\n","#register_env(select_env, lambda config: VizdoomEnv())\n","\n","print(\"registered environment\")\n"]},{"cell_type":"markdown","source":["Training config"],"metadata":{"id":"hdrehMYidzyk"}},{"cell_type":"code","source":["# configure the environment and create agent\n","config = ppo.DEFAULT_CONFIG.copy()\n","config[\"log_level\"] = \"WARN\"\n","#config[\"num_workers\"] = 1\n","config[\"framework\"] = \"torch\"\n","config[\"model\"] = {\"dim\": 42, \n","                   \"grayscale\": True,\n","                   }\n","config[\"num_gpus\"] = 1\n","config[\"preprocessor_pref\"] = \"rllib\"\n","config['explore'] = True \n","#config['batch_mode'] = 'complete_episodes'\n"],"metadata":{"id":"8nXxHPHWd22e","executionInfo":{"status":"ok","timestamp":1663590638220,"user_tz":-60,"elapsed":359,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":876,"status":"ok","timestamp":1663591810992,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"},"user_tz":-60},"id":"yWJlycXSNVJ7","outputId":"97ba73fb-f775-4bfe-bd99-4ae5bc171ed2"},"outputs":[{"output_type":"stream","name":"stdout","text":["config file: /content/drive/MyDrive/GitHub/INM363-Project/scenarios/custom/very_dense_reward.cfg\n","scenario file: /content/drive/MyDrive/GitHub/INM363-Project/scenarios/custom/train/easy_no_reward_rs.wad\n","episode timeout: 400\n","screen resolution: 320X240\n"]},{"output_type":"stream","name":"stderr","text":["2022-09-19 12:50:11,327\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"]},{"output_type":"stream","name":"stdout","text":["created agent\n"]}],"source":["\n","#activating curiosity as the exploration class : https://docs.ray.io/en/latest/rllib/rllib-algorithms.html\n","\n","#set to 0 because of: https://discuss.ray.io/t/scaling-curiosity-like-exploration-modules-on-multiple-workers/2267\n","config[\"num_workers\"] = 0 #check why this is set to 0!  \n","\n","config[\"exploration_config\"] = {\n","    \"type\": \"Curiosity\",  # <- Use the Curiosity module for exploring.\n","    \"eta\": 0.01, #0.001,  # Weight for intrinsic rewards before being added to extrinsic ones.\n","    \"lr\": 0.001,  # Learning rate of the curiosity (ICM) module.\n","    \"feature_dim\": 288,  # Dimensionality of the generated feature vectors.\n","    # Setup of the feature net (used to encode observations into feature (latent) vectors).\n","    \"feature_net_config\": {\n","        \"fcnet_hiddens\": [],\n","        \"fcnet_activation\": \"relu\",\n","    },\n","    \"inverse_net_hiddens\": [256],  # Hidden layers of the \"inverse\" model.\n","    \"inverse_net_activation\": \"relu\",  # Activation of the \"inverse\" model.\n","    \"forward_net_hiddens\": [256],  # Hidden layers of the \"forward\" model.\n","    \"forward_net_activation\": \"relu\",  # Activation of the \"forward\" model.\n","    \"beta\": 0.2,  # Weight for the \"forward\" loss (beta) over the \"inverse\" loss (1.0 - beta).\n","    # Specify, which exploration sub-type to use (usually, the algo's \"default\"\n","    # exploration, e.g. EpsilonGreedy for DQN, StochasticSampling for PG/SAC).\n","    \"sub_exploration\": {\n","        \"type\": \"StochasticSampling\",\n","    }\n","}\n","\n","\n","\"\"\"\n","used vf_clip = 400 for easy and new_dense settings \n","= 600 for sparse settings \n","\"\"\"\n","\n","#config[\"vf_clip_param\"] = 600\n","\n","#changed due to warning\n","# Clip param for the value function. Note that this is sensitive to the\n","# scale of the rewards. If your expected V is large, increase this. (previosuly 10) \n","#2022-08-30 17:15:25,928\tWARNING ppo.py:465 -- The mean reward returned from the environment is 5066.82568359375 but the\n","# vf_clip_param is set to 100. Consider increasing it for policy: default_policy to improve value function convergence.\n","\n","#config[\"vf_clip_param\"] = 10000  # changin this back to try scaled reward setting \n","#100\n","#2022-09-01 12:20:27,151\tWARNING ppo.py:465 -- The mean reward returned from the environment is 16827.6640625 but the vf_clip_param is set to 10.0. Consider increasing it for policy: default_policy to improve value function convergence.\n","\n","\n","\n","agent = ppo.PPOTrainer(config, env=select_env)\n","\n","print(\"created agent\")"]},{"cell_type":"markdown","source":["Training loop"],"metadata":{"id":"P6ugiKigfIZa"}},{"cell_type":"code","source":["import pandas as pd\n","import time \n","\n","cols = [\"checkpoint\", \"eps_reward_min\", \"eps_reward_mean\", \"eps_reward_max\", \"eps_len_mean\", \"episodes_this_iter\"]\n","results_df = pd.DataFrame(columns = cols) "],"metadata":{"id":"CyIb7b6HfM4D","executionInfo":{"status":"ok","timestamp":1663591816102,"user_tz":-60,"elapsed":543,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#chkpt_root = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/icm/sparse\"\n","#chkpt_file  = \"/content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/icm/sparse/checkpoint_000140\"\n","#agent.restore(chkpt_file)"],"metadata":{"id":"_razBAutilbw","executionInfo":{"status":"ok","timestamp":1663591816710,"user_tz":-60,"elapsed":2,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"iYkFV63oJIb6","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1663593484994,"user_tz":-60,"elapsed":1667345,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}},"outputId":"8cb30c19-581b-4aa9-86fe-642ac313e32b"},"outputs":[{"output_type":"stream","name":"stdout","text":["started training loop\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n","WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"]},{"output_type":"stream","name":"stdout","text":["Saved checkpoint 1 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/icm/easy_no_reward/checkpoint_000001\n"," 1 reward   0.00/  0.00/  0.00 len 95.32\n"," 2 reward   0.00/  0.00/  0.00 len 95.35\n"," 3 reward   0.00/  0.00/  0.00 len 90.47\n"," 4 reward   0.00/  0.00/  0.00 len 85.78\n"," 5 reward   0.00/  0.00/  0.00 len 87.61\n"," 6 reward   0.00/  0.00/  0.00 len 87.47\n"," 7 reward   0.00/  0.00/  0.00 len 84.62\n"," 8 reward   0.00/  0.00/  0.00 len 89.53\n"," 9 reward   0.00/  0.00/  0.00 len 92.41\n","Saved checkpoint 10 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/icm/easy_no_reward/checkpoint_000010\n","10 reward   0.00/  0.00/  0.00 len 90.53\n","11 reward   0.00/  0.00/  0.00 len 90.61\n","12 reward   0.00/  0.00/  0.00 len 92.49\n","13 reward   0.00/  0.00/  0.00 len 93.40\n","14 reward   0.00/  0.00/  0.00 len 90.56\n","15 reward   0.00/  0.00/  0.00 len 89.61\n","16 reward   0.00/  0.00/  0.00 len 89.66\n","17 reward   0.00/  0.00/  0.00 len 92.47\n","18 reward   0.00/  0.00/  0.00 len 91.43\n","19 reward   0.00/  0.00/  0.00 len 91.36\n","Saved checkpoint 20 at /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/icm/easy_no_reward/checkpoint_000020\n","20 reward   0.00/  0.00/  0.00 len 90.44\n","21 reward   0.00/  0.00/  0.00 len 89.57\n","22 reward   0.00/  0.00/  0.00 len 90.45\n","23 reward   0.00/  0.00/  0.00 len 87.48\n","24 reward   0.00/  0.00/  0.00 len 89.48\n","25 reward   0.00/  0.00/  0.00 len 88.56\n","26 reward   0.00/  0.00/  0.00 len 90.44\n","27 reward   0.00/  0.00/  0.00 len 88.49\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mViZDoomUnexpectedExitException\u001b[0m            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/env/vector_env.py\u001b[0m in \u001b[0;36mvector_step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/GitHub/INM363-Project/src/vizdoom_gym/envs/VizDoomEnv.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_repeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mViZDoomUnexpectedExitException\u001b[0m: Controlled ViZDoom instance exited unexpectedly.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-d021bd1850b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#change this to  10 or 20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/trainable/trainable.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warmup_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"step() needs to return a dict.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/algorithms/algorithm.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;31m#   evaluate after the training iteration is entirely done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_training_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;31m# Sequential: Train (already done above), then evaluate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/algorithms/algorithm.py\u001b[0m in \u001b[0;36m_run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2371\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRAINING_ITERATION_TIMER\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_disable_execution_plan_api\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2373\u001b[0;31m                             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2374\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m                             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exec_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/algorithms/ppo/ppo.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             train_batch = synchronous_parallel_sample(\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mworker_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_env_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             )\n\u001b[1;32m    410\u001b[0m         \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_multi_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/execution/rollout_ops.py\u001b[0m in \u001b[0;36msynchronous_parallel_sample\u001b[0;34m(worker_set, max_agent_steps, max_env_steps, concat)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# samples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mworker_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0msample_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mworker_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Loop over remote workers' `sample()` method in parallel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    804\u001b[0m             )\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         steps_so_far = (\n\u001b[1;32m    808\u001b[0m             \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/sampler.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSampleBatchType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extra_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/sampler.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSampleBatchType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env_runner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRolloutMetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/sampler.py\u001b[0m in \u001b[0;36m_env_runner\u001b[0;34m(worker, base_env, extra_batch_callback, horizon, normalize_actions, clip_actions, multiple_episodes_in_batch, callbacks, perf_stats, soft_horizon, no_done_at_end, observation_fn, sample_collector, render)\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;31m# taken off-policy actions; those envs are free to ignore the action.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mt4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         \u001b[0mbase_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions_to_send\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         \u001b[0mperf_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"env_wait_time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_poll_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/env/vector_env.py\u001b[0m in \u001b[0;36msend_actions\u001b[0;34m(self, action_dict)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_dones\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_infos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         ) = self.vector_env.vector_step(action_vector)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/env/vector_env.py\u001b[0m in \u001b[0;36mvector_step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart_failed_sub_environments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["status = \"{:2d} reward {:6.2f}/{:6.2f}/{:6.2f} len {:4.2f}\"\n","start_n = 0 \n","n_iter = 200\n","\n","print(\"started training loop\")\n","time_start = time.time() \n","\n","# train a policy with RLlib using PPO\n","for n in range(start_n, n_iter):\n","  \n","    result = agent.train()\n","\n","    #change this to  10 or 20 \n","    if (n+1) % 10 == 0 or n == 0: \n","      chkpt_file = agent.save(chkpt_root)\n","      print(f\"Saved checkpoint {n+1} at {chkpt_file}\")\n","    #chkpt_file = \"not saving checkpoints\"\n","\n","    print(status.format(\n","        n + 1,\n","        result[\"episode_reward_min\"],\n","        result[\"episode_reward_mean\"],\n","        result[\"episode_reward_max\"],\n","        result[\"episode_len_mean\"]\n","    ))\n","\n","    #save metrics\n","    row = {'checkpoint': n+1,\n","       \"eps_reward_min\": result[\"episode_reward_min\"],\n","       \"eps_reward_mean\": result[\"episode_reward_mean\"],\n","       \"eps_reward_max\": result[\"episode_reward_max\"],\n","       \"eps_len_mean\": result[\"episode_len_mean\"],\n","       \"episodes_this_iter\": result[\"episodes_this_iter\"]\n","       }\n","    results_df = results_df.append(row, ignore_index = True)\n","\n","\n","print(f\"Total time elapsed: {(time.time()-time_start)/60}\")\n","\n","print(\"ending training loop\")\n","\n","ray.shutdown()\n","print(\"shutdown ray\")"]},{"cell_type":"markdown","source":["# save results file"],"metadata":{"id":"swoA5eWlfaPu"}},{"cell_type":"code","source":["from pathlib import Path \n","\n","fname = chkpt_root + '/result.csv'\n","fpath = Path(fname)\n","fpath.parent.mkdir(parents=True, exist_ok = True)\n","results_df.to_csv(fpath)\n","print(f\"Saved results file to {fname}\")\n"],"metadata":{"id":"GbY_mDnLnWIS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663593491278,"user_tz":-60,"elapsed":397,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}},"outputId":"5f08da07-2d63-421b-de3b-49d1bc7f7581"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved results file to /content/drive/MyDrive/GitHub/INM363-Project/model_checkpoints/icm/easy_no_reward/result.csv\n"]}]},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bk4jSbh1Yk4z","executionInfo":{"status":"ok","timestamp":1663458977527,"user_tz":-60,"elapsed":23,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}},"outputId":"d4ba8b8f-59df-4abe-d250-62913efeb3a4"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'custom_metrics': {},\n"," 'episode_media': {},\n"," 'num_recreated_workers': 0,\n"," 'info': {'learner': {'default_policy': {'custom_metrics': {},\n","    'learner_stats': {'cur_kl_coeff': 2.8832519531249994,\n","     'cur_lr': 5.0000000000000016e-05,\n","     'total_loss': 599.9217031171245,\n","     'policy_loss': -0.10544964313827535,\n","     'vf_loss': 600.0,\n","     'vf_explained_var': -2.484552321895476e-05,\n","     'kl': 0.009417383247753439,\n","     'entropy': 0.7577878890498992,\n","     'entropy_coeff': 0.0},\n","    'model': {}}},\n","  'num_env_steps_sampled': 800000,\n","  'num_env_steps_trained': 800000,\n","  'num_agent_steps_sampled': 800000,\n","  'num_agent_steps_trained': 800000},\n"," 'sampler_results': {'episode_reward_max': 10.0,\n","  'episode_reward_min': 0.0,\n","  'episode_reward_mean': 1.09,\n","  'episode_len_mean': 185.88,\n","  'episode_media': {},\n","  'episodes_this_iter': 21,\n","  'policy_reward_min': {},\n","  'policy_reward_max': {},\n","  'policy_reward_mean': {},\n","  'custom_metrics': {},\n","  'hist_stats': {'episode_reward': [0.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    0.0,\n","    10.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    10.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    10.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    10.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    10.0,\n","    1.0,\n","    2.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    0.0,\n","    10.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    1.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    0.0,\n","    10.0,\n","    1.0,\n","    1.0,\n","    0.0,\n","    0.0,\n","    2.0,\n","    10.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    1.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    1.0,\n","    1.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    0.0,\n","    1.0,\n","    0.0],\n","   'episode_lengths': [200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    6,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    103,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    8,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    3,\n","    200,\n","    200,\n","    200,\n","    200,\n","    10,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    44,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    5,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    9,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200,\n","    200]},\n","  'sampler_perf': {'mean_raw_obs_processing_ms': 1.5897566163460368,\n","   'mean_inference_ms': 3.7915034519970887,\n","   'mean_action_processing_ms': 0.06726743593842494,\n","   'mean_env_wait_ms': 0.9264538922203015,\n","   'mean_env_render_ms': 0.0},\n","  'num_faulty_episodes': 0},\n"," 'episode_reward_max': 10.0,\n"," 'episode_reward_min': 0.0,\n"," 'episode_reward_mean': 1.09,\n"," 'episode_len_mean': 185.88,\n"," 'episodes_this_iter': 21,\n"," 'policy_reward_min': {},\n"," 'policy_reward_max': {},\n"," 'policy_reward_mean': {},\n"," 'hist_stats': {'episode_reward': [0.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   0.0,\n","   10.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   10.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   10.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   10.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   10.0,\n","   1.0,\n","   2.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   0.0,\n","   10.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   1.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   0.0,\n","   10.0,\n","   1.0,\n","   1.0,\n","   0.0,\n","   0.0,\n","   2.0,\n","   10.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   1.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   1.0,\n","   1.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   0.0,\n","   1.0,\n","   0.0],\n","  'episode_lengths': [200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   6,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   103,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   8,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   3,\n","   200,\n","   200,\n","   200,\n","   200,\n","   10,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   44,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   5,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   9,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200,\n","   200]},\n"," 'sampler_perf': {'mean_raw_obs_processing_ms': 1.5897566163460368,\n","  'mean_inference_ms': 3.7915034519970887,\n","  'mean_action_processing_ms': 0.06726743593842494,\n","  'mean_env_wait_ms': 0.9264538922203015,\n","  'mean_env_render_ms': 0.0},\n"," 'num_faulty_episodes': 0,\n"," 'num_healthy_workers': 0,\n"," 'num_agent_steps_sampled': 800000,\n"," 'num_agent_steps_trained': 800000,\n"," 'num_env_steps_sampled': 800000,\n"," 'num_env_steps_trained': 800000,\n"," 'num_env_steps_sampled_this_iter': 4000,\n"," 'num_env_steps_trained_this_iter': 4000,\n"," 'timesteps_total': 800000,\n"," 'num_steps_trained_this_iter': 4000,\n"," 'agent_timesteps_total': 800000,\n"," 'timers': {'training_iteration_time_ms': 39381.284,\n","  'load_time_ms': 392.002,\n","  'load_throughput': 10204.036,\n","  'learn_time_ms': 13274.204,\n","  'learn_throughput': 301.336},\n"," 'counters': {'num_env_steps_sampled': 800000,\n","  'num_env_steps_trained': 800000,\n","  'num_agent_steps_sampled': 800000,\n","  'num_agent_steps_trained': 800000},\n"," 'done': False,\n"," 'episodes_total': 4747,\n"," 'training_iteration': 200,\n"," 'trial_id': 'default',\n"," 'experiment_id': '9a36c4fb18cb4376913290a0ad4f39fd',\n"," 'date': '2022-09-17_23-56-15',\n"," 'timestamp': 1663458975,\n"," 'time_this_iter_s': 39.35692095756531,\n"," 'time_total_s': 7948.397305965424,\n"," 'pid': 29651,\n"," 'hostname': '62db856a0b31',\n"," 'node_ip': '172.28.0.2',\n"," 'config': {'extra_python_environs_for_driver': {},\n","  'extra_python_environs_for_worker': {},\n","  'num_gpus': 1,\n","  'num_cpus_per_worker': 1,\n","  'num_gpus_per_worker': 0,\n","  '_fake_gpus': False,\n","  'custom_resources_per_worker': {},\n","  'placement_strategy': 'PACK',\n","  'eager_tracing': False,\n","  'eager_max_retraces': 20,\n","  'tf_session_args': {'intra_op_parallelism_threads': 2,\n","   'inter_op_parallelism_threads': 2,\n","   'gpu_options': {'allow_growth': True},\n","   'log_device_placement': False,\n","   'device_count': {'CPU': 1},\n","   'allow_soft_placement': True},\n","  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n","   'inter_op_parallelism_threads': 8},\n","  'env': 'VizDoomVeryDenseReward-v0',\n","  'env_config': {},\n","  'observation_space': None,\n","  'action_space': None,\n","  'env_task_fn': None,\n","  'render_env': False,\n","  'clip_rewards': None,\n","  'normalize_actions': True,\n","  'clip_actions': False,\n","  'disable_env_checking': False,\n","  'num_workers': 0,\n","  'num_envs_per_worker': 1,\n","  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n","  'sample_async': False,\n","  'enable_connectors': False,\n","  'rollout_fragment_length': 200,\n","  'batch_mode': 'truncate_episodes',\n","  'remote_worker_envs': False,\n","  'remote_env_batch_wait_ms': 0,\n","  'validate_workers_after_construction': True,\n","  'ignore_worker_failures': False,\n","  'recreate_failed_workers': False,\n","  'restart_failed_sub_environments': False,\n","  'num_consecutive_worker_failures_tolerance': 100,\n","  'horizon': None,\n","  'soft_horizon': False,\n","  'no_done_at_end': False,\n","  'preprocessor_pref': 'rllib',\n","  'observation_filter': 'NoFilter',\n","  'synchronize_filters': True,\n","  'compress_observations': False,\n","  'enable_tf1_exec_eagerly': False,\n","  'sampler_perf_stats_ema_coef': None,\n","  'gamma': 0.99,\n","  'lr': 5e-05,\n","  'train_batch_size': 4000,\n","  'model': {'_use_default_native_models': False,\n","   '_disable_preprocessor_api': False,\n","   '_disable_action_flattening': False,\n","   'fcnet_hiddens': [256, 256],\n","   'fcnet_activation': 'tanh',\n","   'conv_filters': None,\n","   'conv_activation': 'relu',\n","   'post_fcnet_hiddens': [],\n","   'post_fcnet_activation': 'relu',\n","   'free_log_std': False,\n","   'no_final_linear': False,\n","   'vf_share_layers': False,\n","   'use_lstm': False,\n","   'max_seq_len': 20,\n","   'lstm_cell_size': 256,\n","   'lstm_use_prev_action': False,\n","   'lstm_use_prev_reward': False,\n","   '_time_major': False,\n","   'use_attention': False,\n","   'attention_num_transformer_units': 1,\n","   'attention_dim': 64,\n","   'attention_num_heads': 1,\n","   'attention_head_dim': 32,\n","   'attention_memory_inference': 50,\n","   'attention_memory_training': 50,\n","   'attention_position_wise_mlp_dim': 32,\n","   'attention_init_gru_gate_bias': 2.0,\n","   'attention_use_n_prev_actions': 0,\n","   'attention_use_n_prev_rewards': 0,\n","   'framestack': True,\n","   'dim': 42,\n","   'grayscale': True,\n","   'zero_mean': True,\n","   'custom_model': None,\n","   'custom_model_config': {},\n","   'custom_action_dist': None,\n","   'custom_preprocessor': None,\n","   'lstm_use_prev_action_reward': -1},\n","  'optimizer': {},\n","  'explore': True,\n","  'exploration_config': {'type': 'Curiosity',\n","   'eta': 0.01,\n","   'lr': 0.001,\n","   'feature_dim': 288,\n","   'feature_net_config': {'fcnet_hiddens': [], 'fcnet_activation': 'relu'},\n","   'inverse_net_hiddens': [256],\n","   'inverse_net_activation': 'relu',\n","   'forward_net_hiddens': [256],\n","   'forward_net_activation': 'relu',\n","   'beta': 0.2,\n","   'sub_exploration': {'type': 'StochasticSampling'}},\n","  'input_config': {},\n","  'actions_in_input_normalized': False,\n","  'postprocess_inputs': False,\n","  'shuffle_buffer_size': 0,\n","  'output': None,\n","  'output_config': {},\n","  'output_compress_columns': ['obs', 'new_obs'],\n","  'output_max_file_size': 67108864,\n","  'evaluation_interval': None,\n","  'evaluation_duration': 10,\n","  'evaluation_duration_unit': 'episodes',\n","  'evaluation_sample_timeout_s': 180.0,\n","  'evaluation_parallel_to_training': False,\n","  'evaluation_config': {'extra_python_environs_for_driver': {},\n","   'extra_python_environs_for_worker': {},\n","   'num_gpus': 1,\n","   'num_cpus_per_worker': 1,\n","   'num_gpus_per_worker': 0,\n","   '_fake_gpus': False,\n","   'custom_resources_per_worker': {},\n","   'placement_strategy': 'PACK',\n","   'eager_tracing': False,\n","   'eager_max_retraces': 20,\n","   'tf_session_args': {'intra_op_parallelism_threads': 2,\n","    'inter_op_parallelism_threads': 2,\n","    'gpu_options': {'allow_growth': True},\n","    'log_device_placement': False,\n","    'device_count': {'CPU': 1},\n","    'allow_soft_placement': True},\n","   'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n","    'inter_op_parallelism_threads': 8},\n","   'env': 'VizDoomVeryDenseReward-v0',\n","   'env_config': {},\n","   'observation_space': None,\n","   'action_space': None,\n","   'env_task_fn': None,\n","   'render_env': False,\n","   'clip_rewards': None,\n","   'normalize_actions': True,\n","   'clip_actions': False,\n","   'disable_env_checking': False,\n","   'num_workers': 0,\n","   'num_envs_per_worker': 1,\n","   'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n","   'sample_async': False,\n","   'enable_connectors': False,\n","   'rollout_fragment_length': 200,\n","   'batch_mode': 'truncate_episodes',\n","   'remote_worker_envs': False,\n","   'remote_env_batch_wait_ms': 0,\n","   'validate_workers_after_construction': True,\n","   'ignore_worker_failures': False,\n","   'recreate_failed_workers': False,\n","   'restart_failed_sub_environments': False,\n","   'num_consecutive_worker_failures_tolerance': 100,\n","   'horizon': None,\n","   'soft_horizon': False,\n","   'no_done_at_end': False,\n","   'preprocessor_pref': 'rllib',\n","   'observation_filter': 'NoFilter',\n","   'synchronize_filters': True,\n","   'compress_observations': False,\n","   'enable_tf1_exec_eagerly': False,\n","   'sampler_perf_stats_ema_coef': None,\n","   'gamma': 0.99,\n","   'lr': 5e-05,\n","   'train_batch_size': 4000,\n","   'model': {'_use_default_native_models': False,\n","    '_disable_preprocessor_api': False,\n","    '_disable_action_flattening': False,\n","    'fcnet_hiddens': [256, 256],\n","    'fcnet_activation': 'tanh',\n","    'conv_filters': None,\n","    'conv_activation': 'relu',\n","    'post_fcnet_hiddens': [],\n","    'post_fcnet_activation': 'relu',\n","    'free_log_std': False,\n","    'no_final_linear': False,\n","    'vf_share_layers': False,\n","    'use_lstm': False,\n","    'max_seq_len': 20,\n","    'lstm_cell_size': 256,\n","    'lstm_use_prev_action': False,\n","    'lstm_use_prev_reward': False,\n","    '_time_major': False,\n","    'use_attention': False,\n","    'attention_num_transformer_units': 1,\n","    'attention_dim': 64,\n","    'attention_num_heads': 1,\n","    'attention_head_dim': 32,\n","    'attention_memory_inference': 50,\n","    'attention_memory_training': 50,\n","    'attention_position_wise_mlp_dim': 32,\n","    'attention_init_gru_gate_bias': 2.0,\n","    'attention_use_n_prev_actions': 0,\n","    'attention_use_n_prev_rewards': 0,\n","    'framestack': True,\n","    'dim': 42,\n","    'grayscale': True,\n","    'zero_mean': True,\n","    'custom_model': None,\n","    'custom_model_config': {},\n","    'custom_action_dist': None,\n","    'custom_preprocessor': None,\n","    'lstm_use_prev_action_reward': -1},\n","   'optimizer': {},\n","   'explore': True,\n","   'exploration_config': {'type': 'Curiosity',\n","    'eta': 0.01,\n","    'lr': 0.001,\n","    'feature_dim': 288,\n","    'feature_net_config': {'fcnet_hiddens': [], 'fcnet_activation': 'relu'},\n","    'inverse_net_hiddens': [256],\n","    'inverse_net_activation': 'relu',\n","    'forward_net_hiddens': [256],\n","    'forward_net_activation': 'relu',\n","    'beta': 0.2,\n","    'sub_exploration': {'type': 'StochasticSampling'}},\n","   'input_config': {},\n","   'actions_in_input_normalized': False,\n","   'postprocess_inputs': False,\n","   'shuffle_buffer_size': 0,\n","   'output': None,\n","   'output_config': {},\n","   'output_compress_columns': ['obs', 'new_obs'],\n","   'output_max_file_size': 67108864,\n","   'evaluation_interval': None,\n","   'evaluation_duration': 10,\n","   'evaluation_duration_unit': 'episodes',\n","   'evaluation_sample_timeout_s': 180.0,\n","   'evaluation_parallel_to_training': False,\n","   'evaluation_config': {},\n","   'off_policy_estimation_methods': {},\n","   'evaluation_num_workers': 0,\n","   'always_attach_evaluation_results': False,\n","   'in_evaluation': False,\n","   'sync_filters_on_rollout_workers_timeout_s': 60.0,\n","   'keep_per_episode_custom_metrics': False,\n","   'metrics_episode_collection_timeout_s': 60.0,\n","   'metrics_num_episodes_for_smoothing': 100,\n","   'min_time_s_per_iteration': None,\n","   'min_train_timesteps_per_iteration': 0,\n","   'min_sample_timesteps_per_iteration': 0,\n","   'logger_creator': None,\n","   'logger_config': None,\n","   'log_level': 'WARN',\n","   'log_sys_usage': True,\n","   'fake_sampler': False,\n","   'seed': None,\n","   '_tf_policy_handles_more_than_one_loss': False,\n","   '_disable_preprocessor_api': False,\n","   '_disable_action_flattening': False,\n","   '_disable_execution_plan_api': True,\n","   'simple_optimizer': False,\n","   'monitor': -1,\n","   'evaluation_num_episodes': -1,\n","   'metrics_smoothing_episodes': -1,\n","   'timesteps_per_iteration': -1,\n","   'min_iter_time_s': -1,\n","   'collect_metrics_timeout': -1,\n","   'buffer_size': -1,\n","   'prioritized_replay': -1,\n","   'learning_starts': -1,\n","   'replay_batch_size': -1,\n","   'replay_sequence_length': None,\n","   'prioritized_replay_alpha': -1,\n","   'prioritized_replay_beta': -1,\n","   'prioritized_replay_eps': -1,\n","   'min_time_s_per_reporting': -1,\n","   'min_train_timesteps_per_reporting': -1,\n","   'min_sample_timesteps_per_reporting': -1,\n","   'input_evaluation': -1,\n","   'lr_schedule': None,\n","   'use_critic': True,\n","   'use_gae': True,\n","   'kl_coeff': 0.2,\n","   'sgd_minibatch_size': 128,\n","   'num_sgd_iter': 30,\n","   'shuffle_sequences': True,\n","   'vf_loss_coeff': 1.0,\n","   'entropy_coeff': 0.0,\n","   'entropy_coeff_schedule': None,\n","   'clip_param': 0.3,\n","   'vf_clip_param': 600,\n","   'grad_clip': None,\n","   'kl_target': 0.01,\n","   'vf_share_layers': -1,\n","   'lambda': 1.0,\n","   'input': 'sampler',\n","   'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec at 0x7f9c10046b50>},\n","    'policy_map_capacity': 100,\n","    'policy_map_cache': None,\n","    'policy_mapping_fn': None,\n","    'policies_to_train': None,\n","    'observation_fn': None,\n","    'replay_mode': 'independent',\n","    'count_steps_by': 'env_steps'},\n","   'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n","   'create_env_on_driver': False,\n","   'custom_eval_function': None,\n","   'framework': 'torch',\n","   'num_cpus_for_driver': 1},\n","  'off_policy_estimation_methods': {},\n","  'evaluation_num_workers': 0,\n","  'always_attach_evaluation_results': False,\n","  'in_evaluation': False,\n","  'sync_filters_on_rollout_workers_timeout_s': 60.0,\n","  'keep_per_episode_custom_metrics': False,\n","  'metrics_episode_collection_timeout_s': 60.0,\n","  'metrics_num_episodes_for_smoothing': 100,\n","  'min_time_s_per_iteration': None,\n","  'min_train_timesteps_per_iteration': 0,\n","  'min_sample_timesteps_per_iteration': 0,\n","  'logger_creator': None,\n","  'logger_config': None,\n","  'log_level': 'WARN',\n","  'log_sys_usage': True,\n","  'fake_sampler': False,\n","  'seed': None,\n","  '_tf_policy_handles_more_than_one_loss': False,\n","  '_disable_preprocessor_api': False,\n","  '_disable_action_flattening': False,\n","  '_disable_execution_plan_api': True,\n","  'simple_optimizer': False,\n","  'monitor': -1,\n","  'evaluation_num_episodes': -1,\n","  'metrics_smoothing_episodes': -1,\n","  'timesteps_per_iteration': -1,\n","  'min_iter_time_s': -1,\n","  'collect_metrics_timeout': -1,\n","  'buffer_size': -1,\n","  'prioritized_replay': -1,\n","  'learning_starts': -1,\n","  'replay_batch_size': -1,\n","  'replay_sequence_length': None,\n","  'prioritized_replay_alpha': -1,\n","  'prioritized_replay_beta': -1,\n","  'prioritized_replay_eps': -1,\n","  'min_time_s_per_reporting': -1,\n","  'min_train_timesteps_per_reporting': -1,\n","  'min_sample_timesteps_per_reporting': -1,\n","  'input_evaluation': -1,\n","  'lr_schedule': None,\n","  'use_critic': True,\n","  'use_gae': True,\n","  'kl_coeff': 0.2,\n","  'sgd_minibatch_size': 128,\n","  'num_sgd_iter': 30,\n","  'shuffle_sequences': True,\n","  'vf_loss_coeff': 1.0,\n","  'entropy_coeff': 0.0,\n","  'entropy_coeff_schedule': None,\n","  'clip_param': 0.3,\n","  'vf_clip_param': 600,\n","  'grad_clip': None,\n","  'kl_target': 0.01,\n","  'vf_share_layers': -1,\n","  'lambda': 1.0,\n","  'input': 'sampler',\n","  'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec at 0x7f9c5c075390>},\n","   'policy_map_capacity': 100,\n","   'policy_map_cache': None,\n","   'policy_mapping_fn': None,\n","   'policies_to_train': None,\n","   'observation_fn': None,\n","   'replay_mode': 'independent',\n","   'count_steps_by': 'env_steps'},\n","  'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n","  'create_env_on_driver': False,\n","  'custom_eval_function': None,\n","  'framework': 'torch',\n","  'num_cpus_for_driver': 1},\n"," 'time_since_restore': 7948.397305965424,\n"," 'timesteps_since_restore': 0,\n"," 'iterations_since_restore': 200,\n"," 'warmup_time': 0.5857417583465576,\n"," 'perf': {'cpu_util_percent': 3.632142857142857,\n","  'ram_util_percent': 5.701785714285715}}"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":[],"metadata":{"id":"9zFP4jZ_imcw","executionInfo":{"status":"ok","timestamp":1663458977527,"user_tz":-60,"elapsed":18,"user":{"displayName":"Priyanka Reddy Velagala","userId":"03260377081952019186"}}},"execution_count":34,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyMdNFjmfVO8ciAmAmapKpVl"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}